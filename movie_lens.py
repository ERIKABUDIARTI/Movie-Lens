# -*- coding: utf-8 -*-
"""Movie Lens.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNyOV6mk01jbnAgwo2r46RKXAQP6eDGY

Proyek Recommendation System: **Movie Lens Dataset**
- Nama:**ERIKA BUDIARTI**
- Email: erika.analytic@gmail.com
- Id Dicoding:erika_budiarti

# **Menghubungkan Kaggle ke Google Colaboratory**

**Mengimport kaggle**
"""

!pip install kaggle

"""**Upload file API Kaggle**"""

from google.colab import files

uploaded = files.upload()

!mkdir -p /content/gdrive/My\ Drive/Kaggle
!mv kaggle.json /content/gdrive/My\ Drive/Kaggle/kaggle.json

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

"""**Upload Dataset dari Kaggle**"""

!kaggle datasets download -d snehal1409/movielens

!unzip movielens.zip

"""# **Data Understanding**

**Import Library**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from math import sqrt
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors

import tensorflow as tf
from tensorflow import keras
from keras import layers

"""**Loading Dataset**"""

movies_df = pd.read_csv('/content/movies.csv')
ratings_df = pd.read_csv('/content/ratings.csv')

"""## **Dataset Movies**

**Menampilkan 5 baris pertama dataset  "Movies"**
"""

movies_df.head()

"""**Menampilkan jumlah baris dan kolom dalam dataset**"""

movies_df.shape

"""**Menampilkan nilai unik pada kolom 'title'**"""

movies_df.title.nunique()

"""**Menampilkan nilai duplikat pada kolom 'title'**"""

duplicate_titles = movies_df[movies_df['title'].duplicated(keep=False)]
print(duplicate_titles['title'])

"""**Drop nilai duplikat pada kolom 'title'**"""

movies_df.drop_duplicates(subset='title', keep='first', inplace=True)
movies_df

"""**Mengubah nama kolom 'title'**"""

movies_df.rename(columns={'title':'title_year'}, inplace=True)
movies_df

"""**Extract kolom 'title' untuk memisahkan dengan 'year'**"""

def extract_title(title_year):

  year = title_year[len(title_year)-5:len(title_year)-1]

  if year.isnumeric():
    title_no_year = title_year[:len(title_year)-7]
    return title_no_year

  else:
    return title_year

def extract_year(title_year):

  year = title_year[len(title_year)-5:len(title_year)-1]

  if year.isnumeric():
    return year
    year = int(year)

  else:
    return np.nan

movies_df['title_year'] = movies_df['title_year'].apply(lambda x: x.strip())
movies_df['title'] = movies_df['title_year'].apply(extract_title)
movies_df['year'] = movies_df['title_year'].apply(extract_year)
movies_df.drop(['title_year'], axis=1, inplace=True)

movies_df.head()

"""**Memisahkan nilai-nilai pada kolom "Genres"**"""

movies_df['genres'] = movies_df.genres.str.split('|')
movies_df.head()

"""**Visualisasi jumlah film untuk setiap genre**"""

movies_df2 = movies_df.explode('genres')

genre_counts = movies_df2['genres'].value_counts()

sns.set_style("whitegrid")
plt.figure(figsize=(12, 6))
sns.barplot(x=genre_counts.index, y=genre_counts.values, palette="Blues_d")
plt.xlabel('Genres')
plt.ylabel('Counts')
plt.title('Genre Distribution')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""**Menampilkan jumlah missing value pada dataset**"""

movies_df.isna().sum()

"""## **Dataset Ratings**

**Menampilkan 5 baris pertama dari dataset "Ratings"**
"""

ratings_df.head()

"""**Menampilkan jumlah kolom dan baris dalam dataset**"""

ratings_df.shape

"""**Menampilkan data duplikat pada dataset**"""

ratings_df.duplicated().sum()

"""**Menampilkan jumlah missing value pada dataset**"""

ratings_df.isna().sum()

"""**Drop kolom "timestamp"**"""

ratings_df = ratings_df.drop('timestamp', 1)
ratings_df.head()

"""**Menampilkan nilai unik dari variable "rating"**"""

ratings_df['rating'].value_counts().sort_index(ascending=True)

rating_counts = ratings_df['rating'].value_counts().sort_index(ascending=True)

sns.set(style="whitegrid")
custom_palette = sns.color_palette("Purples", n_colors=len(rating_counts))

plt.figure(figsize=(8, 6))
sns.barplot(x=rating_counts.index, y=rating_counts.values, palette="Purples_d")

plt.xlabel('Rating')
plt.ylabel('Count')

plt.title('Rating Distribution')

plt.show()

"""# **Data Preparation**

**Menggabungkan tabel "movies" dan "ratings"**
"""

movie_rating = pd.merge(movies_df, ratings_df, on='movieId')
movie_rating

"""**Encoding "userId" menjadi index numerik**"""

user_ids = movie_rating["userId"].unique().tolist()
user_encoded = {x: i for i, x in enumerate(user_ids)}
userencoded_ = {i: x for i, x in enumerate(user_ids)}
num_users = len(user_encoded)
num_users

"""**Encoding "movieId" menjadi index numerik**"""

movie_ids = movie_rating["movieId"].unique().tolist()
movie_encoded = {x: i for i, x in enumerate(movie_ids)}
movieencoded_ = {i: x for i, x in enumerate(movie_ids)}
num_movies = len(movie_encoded)
num_movies

movie_rating["user"] = movie_rating["userId"].map(user_encoded)
movie_rating["movie"] = movie_rating["movieId"].map(movie_encoded)

movie_rating

"""**Mencari rating tertinggi dan terendah**"""

movie_rating["rating"] = movie_rating["rating"].values.astype(np.float32)

min_rating = min(movie_rating["rating"])
max_rating = max(movie_rating["rating"])

print(
    "Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}".format(
        num_users, num_movies, min_rating, max_rating
    )
)

"""**Memisahkan Fitur dan Target**"""

movie_rating = movie_rating.sample(frac=1, random_state=42)
x = movie_rating[["user", "movie"]].values
y = movie_rating["rating"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

"""**Memisahkan data pelatihan dan data validasi**"""

train_indices = int(0.75 * movie_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:],
)

"""# **Data Training**

**Membangun model**
"""

embedding_size = 50

class RecommenderNet(keras.Model):
    def __init__(self, num_users, num_movies, embedding_size, **kwargs):
        super().__init__(**kwargs)
        self.num_users = num_users
        self.num_movies = num_movies
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.movie_embedding = layers.Embedding(
            num_movies,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.movie_bias = layers.Embedding(num_movies, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])
        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x)

"""**Mendefinisikan model**"""

model = RecommenderNet(num_users, num_movies, embedding_size)

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**Training Model**"""

history = model.fit(
    x_train,
    y_train,
    batch_size=64,
    epochs=5,
    verbose=2,
    validation_data=(x_val, y_val),
)

"""# **Visualisasi Metrik**

**Plot loss dan akurasi**
"""

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.title("Loss Model")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(["train", "validation"], loc="upper right")
plt.show()

plt.plot(history.history["root_mean_squared_error"])
plt.plot(history.history["val_root_mean_squared_error"])
plt.title("RMSE Model")
plt.ylabel("RMSE")
plt.xlabel("epoch")
plt.legend(["train", "validation"], loc="upper right")
plt.show()

"""# **Model Development - Collaborative Filtering**

**Top Movies**
"""

user_id = movie_rating.userId.sample(1).iloc[0]

movies_watched = movie_rating[movie_rating.userId == user_id]

movies_notwatched = movie_rating[~movie_rating["movieId"].isin(movies_watched.movieId.values)]["movieId"]
movies_notwatched = list(set(movies_notwatched).intersection(set(movie_encoded.keys())))
movies_notwatched = [[movie_encoded.get(x)] for x in movies_notwatched]

user_encoder = user_encoded.get(user_id)
user_movie_array = np.hstack(([[user_encoder]] * len(movies_notwatched), movies_notwatched))

ratings = model.predict(user_movie_array).flatten()
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movieencoded_.get(movies_notwatched[x][0]) for x in top_ratings_indices
]

print("Tampilkan Rekomendasi Film untuk {} Penonton ".format(num_users))

"""**5 Film dengan rating tertinggi**"""

print("====" * 9)

print("Top 5 Film dengan Rating Tertinggi")

print("====" * 9)

top_movies_user = movies_watched.sort_values(by="rating", ascending=False).head(5)
for index, row in top_movies_user.iterrows():
    print(row.title, ":", row.genres)

"""**Top 10 Rekomendasi Film**"""

print("====" * 6)

print("Top 10 Rekomendasi Film")

print("====" * 6)

recommended_movie_ids = []
for x in top_ratings_indices:
    movie_id = movieencoded_.get(movies_notwatched[x][0])
    if movie_id not in recommended_movie_ids:
        recommended_movie_ids.append(movie_id)

movie_rating_unique = movie_rating.drop_duplicates(subset="movieId")
recommended_movies = movie_rating_unique[movie_rating_unique["movieId"].isin(recommended_movie_ids)].head(10)
for index, row in recommended_movies.iterrows():
    print(row.title, ":", row.genres)

rm = recommended_movies.groupby('title')['rating'].max()
rt = rm.sort_values(ascending=False)

titles = rt.index
ratings = rt.values
palette = sns.color_palette("Greens", n_colors=len(titles))

plt.figure(figsize=(6, 4))
sns.barplot(x=ratings, y=titles, palette=palette)
plt.xlabel('Rating', fontsize=12)
plt.ylabel('Title', fontsize=12)
plt.title('Rating of Recommended Movies')
plt.gca().invert_yaxis()
plt.xlim(0, 5)
plt.xticks(np.arange(0, 5.5, 0.5), fontsize=8)

y_axis_labels = [' '.join(title.split()[:2]) for title in titles]
plt.yticks(range(len(titles)), y_axis_labels, fontsize=8)
plt.show()

"""# **Model Development - Content Based Filtering**

**Membuat pivot table untuk menggabungkan pengguna yang memberikan rating dan jumlah film yang mendapat rating**
"""

no_user_voted = movie_rating.groupby('movieId')['rating'].agg('count')
no_movies_voted = movie_rating.groupby('userId')['rating'].agg('count')

final_dataset = movie_rating.pivot(index='movieId',columns='userId',values='rating')
final_dataset.fillna(0,inplace=True)
final_dataset.head()

"""**Visualisasi jumlah pengguna yang memberikan rating dengan threshold = 10**"""

final_dataset = final_dataset.loc[no_user_voted[no_user_voted > 10].index,:]
final_dataset

sns.set(style="whitegrid")

f, ax = plt.subplots(1, 1, figsize=(16, 4))
sns.scatterplot(data=no_user_voted, x=no_user_voted.index, y=no_user_voted, color='red')
plt.axhline(y=10, color='b')
plt.xlabel('MovieId')
plt.ylabel('No. of users voted')
plt.title('Jumlah Pengguna yang Memberikan Rating per Film (Threshold = 10)')
plt.show()

"""**Visualisasikan jumlah pemberian rating oleh setiap pengguna dengan threshold = 50**"""

final_dataset = final_dataset.loc[:,no_movies_voted[no_movies_voted > 50].index]
final_dataset

sns.set(style="whitegrid")

f, ax = plt.subplots(1, 1, figsize=(16, 4))
sns.scatterplot(data=no_movies_voted, x=no_movies_voted.index, y=no_movies_voted, color='orange')
plt.axhline(y=50, color='g')
plt.xlabel('UserId')
plt.ylabel('No. of votes by user')
plt.title('Jumlah Rating yang Diberikan oleh Setiap Pengguna (Threshold = 50)')
plt.show()

"""**Menggunakan algoritma KNN**"""

csr_data = csr_matrix(final_dataset.values)
final_dataset.reset_index(inplace=True)

knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=30, n_jobs=-1)
knn.fit(csr_data)

def get_movie_recommendation(movie_name):
    n_movies_to_reccomend = 10
    movie_list = movie_rating[movie_rating['title'].str.contains(movie_name)]

    if len(movie_list):
        movie_idx= movie_list.iloc[0]['movieId']
        movie_idx = final_dataset[final_dataset['movieId'] == movie_idx].index[0]
        distances , indices = knn.kneighbors(csr_data[movie_idx],n_neighbors=n_movies_to_reccomend+1)
        rec_movie_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]
        recommend_frame = []

        for val in rec_movie_indices:
            movie_idx = final_dataset.iloc[val[0]]['movieId']
            idx = movie_rating[movie_rating['movieId'] == movie_idx].index
            recommend_frame.append({'Title':movie_rating.iloc[idx]['title'].values[0],'Genres': movie_rating['genres'].values[0], 'Rating': movie_rating['rating'].values[0]})
        df = pd.DataFrame(recommend_frame,index=range(1,n_movies_to_reccomend+1))
        return df

    else:
        return "No movies found. Please check your input"

"""**Rekomendasi Film sesuai user input**"""

rec = get_movie_recommendation('Avengers')
rec

"""**Menghitung Precision Score**"""

movie_relevant = 10
movie_recommendation = len(rec)
precision_score = movie_relevant / movie_recommendation

print("Precision: {:.2f}".format(precision_score))